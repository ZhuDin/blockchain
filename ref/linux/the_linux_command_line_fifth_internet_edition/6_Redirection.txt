6 - Redirection

In this lesson we are going to unleash what may be the coolest feature of the command
line. It's called I/O redirection. The "I/O" stands for input/output and with this facility we
can redirect the input and output of commands to and from files, as well as connect multiple
commands together into powerful command pipelines. To show off this facility, we
will introduce the following commands:

  * cat - Concatenate files
  * sort - Sort lines of text
  * uniq - Report or omit repeated lines
  * grep - Print lines matching a pattern
  * wc - Print newline, word, and byte counts for each file
  * head - Output the first part of a file
  * tail - Output the last part of a file
  * tee - Read from standard input and write to standard output and files


Standard Input, Output, and Error

Many of the programs that we have used so far produce output of some kind. This output
often consists of two types:

  * The program's results, that is, the data the program is designed to produce
  * Status and error messages that tell us how the program is getting along

If we look at a command like ls, we can see that it display its results and its error messages
on the screen.

Keeping with the Unix theme of "everything is a file", programs such as ls acutally send
their results to a special file called standard output (often expressed as stdout) and their
status messages to another file called standard error (stderr). By default, both standard
output and standard error are linked to the screen and not saved into a disk file.

In addition, many programs take input from a facility called standard input (stdin), which
is, by default, attached to the keyboard.

I/O redirection allows us to change where output goes and where input come from. Normally,
output goes to the screen and input comes from the keyboard, but with I/O redirection,
we can change that.


Redirecting Standard Output

I/O redirection allows us to redefine where standard output goes. To redirect standard
output to another file instead of the screen, we use the > direction operator following by
the name of the file.

Simply using the redirection operator with no command preceding it will truncate an existing
file or create a new, empty file.

So, how can we append redirected output to a file instead of overwritting the file from the
beginning? For that, we use the >> redirection operator.

Using the >> operator will result in the output being appended to the file. If the file does
already exist, it is created just as though the > operator ahd been used.


Redirecting Standard Error

Redirecting standard error lacks the ease of a dedicated redirection operator. To redirect
standard error we must refer to its file descriptor. A program can produce output on any
of several numbered file streams. While we have referred to the first three of these file
streams as standard input, output and error, the shell references them internally as file
descriptors 0, 1, and 2, respectively. The shell provides a notation for redirecting files 
using the file descriptor number. Since standard error is the same as file descriptor 
number 2, we can redirect standard error with this notation.

$ ls -l /bin/usr 2> ls-error.txt

The file descriptor "2" is placed immediately before the redirection operator to perform
the redirection of standard error to the file ls-error.txt.


Redirecting Standard Output and Standard Error to One File

There are cases in which we may want to capture all of the output of a command to a simple
file. todo this, we must redirect both standard output and standard error at the same time.
There are two ways to do this. Shown here is the traditional way, which works with old 
versions of the shell:

$ ls -l /bin/usr > ls-output.txt 2>&1

Using this method, we perform two redirections. First we redirect standard output to the
file ls-output.txt and then we redirect file descriptor 2 (standard error) to file
descriptor 1 (standard output) using the notation 2>&1.

  Notice that the order of the redirections is significant. The redirection of standard
  error must always occur after redirecting standard output or it doesn't work.

Recent versions of bash provide a second, more streamlined method of performing this
combined redirection shown here:

$ ls -l /bin/usr &> ls-output.txt

In this example, we use the single notation &> to redirect both standard output and standard
error to the file ls-output.txt. We can also append the standard output and standard error
streams to a single file like so:

$ ls -l /bin/usr &>> ls-output.txt


Disposing of Unwanted Output

Sometimes "silence is golden," and we don't want output from a command, we just want to
throw it away. This applies particularly to error and status messages. The system provides
a way to do this by redirecting output to a special file called "/dev/null". This file is
a system device often referred to as a bit bucket, which accepts input and does nothing
with it. To suppress error messages from a command, we do this:

$ ls -l /bin/usr 2> /dev/null


  /dev/null In Unix Culture

  The bit bucket is an ancient Unix concept and because of its universality, it has
  appeared in many parts of Unix culture. When someone says he/she is sending your 
  comments to /dev/null, now you know what it means.


Redirecting Standard Input

Up to now, we haven't encountered any commands that make use of standard input (actually
we have, but we'll reveal that suprise a little bit alter), so we need to introduce one.


cat - Concatenate Files

The cat command reads one or more files and copies them to standard output like so:

cat [file...]

In most cases, we can think of cat as being analogous to the TYPE command in DOS.
We can use it to display files without paging. 

cat is often used to display short text files. Since cat can accept more than one file as
an argument, it can also be used to join files together. Say we have downloaded a large
file that has been split into multiple parts (multimedia files are often split this way on
Usenet), and we want to join them back together. If the files were named:
movie.mpeg.001   movie.mpeg.002 ... movie.mpeg.099
we could join them back together with this command as follows:

cat move.mpeg.0* > movie.mpeg

Since wildcards always expand in sorted order, the arguments will be arranged in the 
correct order.

This is all well and good, but what does this have to do with standard input? Nothing yet,
but let's try something else. What happens if we enter cat with no arguments?

$ cat

Nothing happens, it just sits there like it's hung. It might seem that way, but it's really 
doing exactly what it's supposed to do

If cat is not given any arguments, it reads from standard input and since standard input
is, by default, attached to the keyboard, it's wainting for use to type something!

Next, type a Ctrl-d (i.e., hold down the Ctrl key and press "d") to tell cat theat it has
reached end of file (EOF) on standard input.

In the absence of filename arguments, cat copies standard input to standard output, so
we see our line of text repeated. We can use this behavior to create short text files. Let's 
say we wanted to create a file called lazy_dog.txt containing the text in our example.
We would do this:

$ cat > lazy_dog.txt
The quick brown fox jumped over the lazy dog.

Type the command followed by the text we want to place in the file. Remember to type
Ctrl-d at the end. Using the command line, we have implemented the world's dumbest
word processor! To see our results, we can use cat to copy the file to stdout again.

$ cat lazy_dog.txt

Before we move on, check out the man page for cat, because it has several interesting options.


Pipelines

The capability of commands to read data from standard input and send to standard output
is utilized by a shell feature called pipelines. Using the pipe opertor | (vertical bar), the
standard output of one command can be piped into the standard input of another.

command1 | command2

To fully demonstrate this, we are going to need some commands. Remember how we said 
there was one we already knew that accepts standard input? It's less. We can use less
to display, page by page, the output of any command that sends its results to standard
output:

$ ls -l /usr/bin | less

This is extremely handy! Using this technique, we can conveniently examine the output
of any command that produces standard output.


  The Difference Between > and |

  At first glance, it may be hard to understand the redirection performed by the
  pipeline operator | versus the redirection operator >. Simply put, the redirection
  operator connects a command with a file, while the pipeline connects the output of
  one command with the input of a second command.

  command1 > file1
  
  command1 | command2


Filters

Pipelines are often used to perform complex operations on data. It is possible to put
several commands together into a pipeline. Frequently, the commands used this way are
referred to as filters. Filters take input, change it somehow, and then output it. The
first one we will try is sort. Imagine we wanted to make a combined list of all the 
executable programs in /bin and /usr/bin, put them in sorted order and view the 
resulting list:

$ ls /bin /usr/bin | sort | less

Since we spcified two directories (/bin and /usr/bin), the output of ls would have
consisted of two sorted lists, one for each directory. By including sort in our pipeline,
we changed the data to produce a single, sorted list.


uniq - Report or Omit Repeated Lines

The uniq command is often used in conjunction with sort. uniq accepts a sorted list
of data from either standard input or a single filename argument (see the uniq man page
for details) and, by default, removes any duplicates from the list. So to make sure our list
has no duplicates (that is, any programs of the same name that appear in both the /bin
and /usr/bin directories), we will add uiq to our pipeline.

$ ls /bin /usr/bin | sort | uniq | less

In this example, we use uniq to remove any duplicates from the output of the sort
command. If we want to see the list of duplicates instead, we add the "-d" option to uniq
like so:

$ ls /bin /usr/bin | sort | uniq -d | less


wc - Print Line, Word, and Byte Counts

The wc(word count) command is used to display the number of lines, words, and bytes
contained in files. The "-l" option limits its output to only report lines. Adding it
to a pipeline is a handy way to count things. To see the number of items we have in our
sorted list, we can do this:

$ ls /bin /usr/bin | sort | uniq | wc -l


grep - Print Lines Matching a Pattern

grep is a powerful program used to find text patterns within files. It's used like this:

grep pattern [file...]

When grep encounters a "pattern" in the file, it prints out the lines containing it. The 
patterns that grep can match can be very complex, but for now we will concentrate on
simple text matches. We'll cover the advanced patterns, called regular expressions in
Chapter 19.

There are a comple of handy options for grep:

  * -i, which causes grep to ignore case when performing the search (normally searhes
    are case sensitive)

  * -v, which tells grep to print only those lines that do not match the pattern.


head/tail - Print First/Last Part of Files

Sometimes we don't want all the output from a command. We may only want the first few
lines or the last few lines. The head command prints the first ten lines of a file, and the
tail commad prints the last ten lines. By default, both commands print ten lines of 
text, but this can be adjusted with the -n option.

tail has an option which allows us to view files in real time. This is useful for watching
the progress of log files as they are being written. 

Using the "-f" option, tail continues to monitor the file, and when new lines are appended,
they immediately appear on the display. This continues until we press Ctrl-c.


tee - Read from Stdin and Output to Stdout and Files

In keeping with our plumbing metaphor, Linux provides a command called tee which
creates a "tee" fitting on our pipe. The tee program reads standard input and copies it to
both standard output (allowing the data to continue down the pipeline) and to one or more
files. This is useful for capturing a pipeline's contents at an intermediate stage of 
processing.


Summing Up

As always, check out the documentation of each of the commands we have covered in
this chapter. We have only their most basic usage. They all have a number of interesting
options. As we gain Linux experience, we will see that the redirection feature of
the command line is extremely useful for solving specialized problems. There are many
commands that make use of standard input and output, and almost all command line programs
use standard error to display hteir informative messages.

